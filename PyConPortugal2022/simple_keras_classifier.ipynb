{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNtMSDxpkIrqiCAmNhsRlh2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/royn5618/Talks_Resources/blob/main/PyConPortugal2022/simple_keras_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**About:**\n",
        "\n",
        "This notebook has naive implmentation of an NLP classifier that predicts emotions.\n",
        "\n",
        "**Data Source on Kaggle:**\n",
        "\n",
        "https://www.kaggle.com/praveengovi/emotions-dataset-for-nlp\n",
        "\n",
        "**Data Source on HuggingFace:**\n",
        "\n",
        "https://huggingface.co/datasets/emotion"
      ],
      "metadata": {
        "id": "g8m5bAN40yyr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data import"
      ],
      "metadata": {
        "id": "jWmHzf8A1VlA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "-IrmN8YI065k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jvmu80Bs0d5-"
      },
      "outputs": [],
      "source": [
        "train_data = pd.read_csv('Data/train.txt', sep=';', names=['text', 'emotion'])\n",
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = pd.read_csv('Data/test.txt', sep=';', names=['text', 'emotion'])\n",
        "test_data.head()"
      ],
      "metadata": {
        "id": "--3STFz21PJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preparation\n",
        "## Label Encoding\n",
        "\n",
        "Encode target labels with value between 0 and n_classes-1."
      ],
      "metadata": {
        "id": "fDc0JxnR1dgl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[\"emotion\"] = train_data[\"emotion\"].astype('category')\n",
        "train_data[\"emotion_label\"] = train_data[\"emotion\"].cat.codes\n",
        "train_data.head()"
      ],
      "metadata": {
        "id": "BUPZycYQ1hXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data[\"emotion\"] = test_data[\"emotion\"].astype('category')\n",
        "test_data[\"emotion_label\"] = test_data[\"emotion\"].cat.codes\n",
        "test_data.head()"
      ],
      "metadata": {
        "id": "Cx1q4sjD1UE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One Hot Encoding\n",
        "\n",
        "Encode categorical features as a one-hot numeric array.\n",
        "For example:\n",
        "\n",
        "```\n",
        "0 -> [1, 0, 0, 0, 0, 0]\n",
        "1 -> [0, 1, 0, 0, 0, 0]\n",
        "...\n",
        "5 -> [0, 0, 0, 0, 0, 1]\n",
        "\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qdwfWM3-3RU8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "GO90VaQA3Q_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features, train_labels = train_data['text'], tf.one_hot(train_data[\"emotion_label\"], 6)\n",
        "test_features, test_labels = test_data['text'], tf.one_hot(test_data[\"emotion_label\"], 6)"
      ],
      "metadata": {
        "id": "5CPXmRXZ1UBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features[:5]"
      ],
      "metadata": {
        "id": "SsvPoIuP1T_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels[:5]"
      ],
      "metadata": {
        "id": "PCmajMJe1T8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decoder\n",
        "\n",
        "Takes in one-hot encoded matrix returns a list of decoded categories. (To be used after predictions)"
      ],
      "metadata": {
        "id": "X1i1Cz3w3uJH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_labels_from_oh_code(oh_code):\n",
        "    \"\"\" Takes in one-hot encoded matrix\n",
        "    Returns a list of decoded categories\"\"\"\n",
        "    label_code = np.argmax(oh_code, axis=1)\n",
        "#     print(label_code)\n",
        "    label = test_data.emotion.cat.categories[label_code]\n",
        "#     print(list(label))\n",
        "    return list(label)"
      ],
      "metadata": {
        "id": "iusKE2o13vH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"Test Method\"\n",
        "test= np.array(train_labels[:5])\n",
        "get_labels_from_oh_code(test)"
      ],
      "metadata": {
        "id": "54BRuOk41T2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Preprocessing\n",
        "\n",
        " - Breaks down a text into smaller units, commonly by the words in it. These words are called tokens and the process is called tokenization.\n",
        "\n",
        " - Keras uses a set of vocabulary and any token out of that vocab list is replaced with OOV. This is a better strategy to tackle unexpected vocab in unseen text data.\n",
        "\n",
        " - For ANNs, usually a standard length is chosen for the each text length. Any text longer is truncated from either front(pre) or back (post), any text shorted padded with zeros either front(pre) or back (post)."
      ],
      "metadata": {
        "id": "3iDU_gDBhPN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "sTiil1p7r4WQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 15000\n",
        "max_seq_len = 20\n",
        "\n",
        "tokenizer = Tokenizer(oov_token = \"<OOV>\", num_words=vocab_size)\n",
        "tokenizer.fit_on_texts(train_data['text'])\n",
        "\n",
        "sequences_train = tokenizer.texts_to_sequences(train_data['text'])\n",
        "sequences_test = tokenizer.texts_to_sequences(test_data['text'])\n",
        "\n",
        "padded_train = pad_sequences(sequences_train, padding = 'post', maxlen=max_seq_len)\n",
        "padded_test = pad_sequences(sequences_test, padding = 'post', maxlen=max_seq_len)"
      ],
      "metadata": {
        "id": "BhiOGcMJhQtK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "id": "lHQ7b0Xdjnwq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build Model\n",
        "\n",
        " - Sequential Model: a linear stack of layers\n",
        " - Embedding Layer: Accepts text input and generates a vectorized (dense) output per token for the given sequence.\n",
        " - Dropout: Discards or randomly ignores a certain fraction of the input.\n",
        " - LSTM: Knows certain information from the past and also learns from new inputs, sequentially, used for texts and time-series modeling.\n",
        " - Dense/Fully-connected layer: Neurons of the layer are connected to every neuron of its preceding layer\n",
        " - Softmax Activation: A mathematical function that converts a vector of numbers into a vector of probabilities, where the probabilities of each value are proportional to the relative scale of each value in the vector"
      ],
      "metadata": {
        "id": "SdXKDIGij0Jw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Dropout, LSTM"
      ],
      "metadata": {
        "id": "MIUXsD7-rx2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_size = 300\n",
        "\n",
        "def get_model():\n",
        "    model = Sequential()\n",
        "    model.add(\n",
        "        Embedding(input_dim=vocab_size,\n",
        "                  output_dim=vector_size,\n",
        "                  input_length=max_seq_len))\n",
        "    model.add(Dropout(0.6))\n",
        "    model.add(LSTM(max_seq_len,return_sequences=True))\n",
        "    model.add(LSTM(6))\n",
        "    model.add(Dense(6,activation='softmax'))\n",
        "    return model"
      ],
      "metadata": {
        "id": "Uns7tQ9q1TzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set Callbacks\n",
        "\n",
        "Enable monitoring model training, saving best models, and get other information or carry out tasks."
      ],
      "metadata": {
        "id": "rUscmjNcpzDI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(monitor=\"val_loss\",\n",
        "                                  patience=2,\n",
        "                                  verbose=1,\n",
        "                                  mode=\"min\",\n",
        "                                  restore_best_weights=True),\n",
        "    keras.callbacks.ModelCheckpoint(filepath='models/best_model.h5',\n",
        "                                    verbose=1,\n",
        "                                    save_best_only=True)\n",
        "]"
      ],
      "metadata": {
        "id": "o8X9V8-KjtKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Verify your model\n",
        "\n",
        "One final view of your model architecture."
      ],
      "metadata": {
        "id": "LKwYaml2p2r2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "A4sc1DRJjtHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compile Model\n",
        "\n",
        "Provide instructions on how the model will learn from its mistakes.\n",
        "\n"
      ],
      "metadata": {
        "id": "VCfLIp5Op7CC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "CkwzKvlmjtE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Model"
      ],
      "metadata": {
        "id": "hgwNcsegq0Bm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(padded_train,\n",
        "                    train_labels,\n",
        "                    validation_split=0.33,\n",
        "                    callbacks=callbacks,\n",
        "                    epochs=10)"
      ],
      "metadata": {
        "id": "Fa5Tg2yzkX_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize and verify the Loss per epoch"
      ],
      "metadata": {
        "id": "-eFqKnt6q2Nb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from plotly.graph_objs import *"
      ],
      "metadata": {
        "id": "pmUB53pKt3q2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric_to_plot = \"loss\"\n",
        "epochs = list(range(1, max(history.epoch) + 2))\n",
        "training_loss = history.history[metric_to_plot]\n",
        "validation_loss = history.history[\"val_\" + metric_to_plot]\n",
        "\n",
        "trace1 = {\n",
        "    \"mode\": \"lines+markers\",\n",
        "    \"name\": \"Training Loss\",\n",
        "    \"type\": \"scatter\",\n",
        "    \"x\": epochs,\n",
        "    \"y\": training_loss\n",
        "}\n",
        "\n",
        "trace2 = {\n",
        "    \"mode\": \"lines+markers\",\n",
        "    \"name\": \"Validation Loss\",\n",
        "    \"type\": \"scatter\",\n",
        "    \"x\": epochs,\n",
        "    \"y\": validation_loss\n",
        "}\n",
        "\n",
        "data = Data([trace1, trace2])\n",
        "layout = {\n",
        "    \"title\": \"Training - Validation Loss\",\n",
        "    \"xaxis\": {\n",
        "        \"title\": \"Number of epochs\",\n",
        "        \"titlefont\": {\n",
        "            \"size\": 18,\n",
        "            \"color\": \"#7f7f7f\"\n",
        "        }\n",
        "    },\n",
        "    \"yaxis\": {\n",
        "        \"title\": \"Loss\",\n",
        "        \"titlefont\": {\n",
        "            \"size\": 18,\n",
        "            \"color\": \"#7f7f7f\"\n",
        "        }\n",
        "    }\n",
        "}\n",
        "fig = Figure(data=data, layout=layout)\n",
        "fig.update_layout(hovermode=\"x unified\")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "hdshwS-DkX9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize and verify the metric per epoch"
      ],
      "metadata": {
        "id": "b4ZE0teWq_I5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metric_to_plot = \"accuracy\"\n",
        "epochs = list(range(1, max(history.epoch) + 2))\n",
        "training_loss = history.history[metric_to_plot]\n",
        "validation_loss = history.history[\"val_\" + metric_to_plot]\n",
        "\n",
        "trace1 = {\n",
        "    \"mode\": \"lines+markers\",\n",
        "    \"name\": \"Training Accuracy\",\n",
        "    \"type\": \"scatter\",\n",
        "    \"x\": epochs,\n",
        "    \"y\": training_loss\n",
        "}\n",
        "\n",
        "trace2 = {\n",
        "    \"mode\": \"lines+markers\",\n",
        "    \"name\": \"Validation Accuracy\",\n",
        "    \"type\": \"scatter\",\n",
        "    \"x\": epochs,\n",
        "    \"y\": validation_loss\n",
        "}\n",
        "\n",
        "data = Data([trace1, trace2])\n",
        "layout = {\n",
        "    \"title\": \"Training - Validation Accuracy\",\n",
        "    \"xaxis\": {\n",
        "        \"title\": \"Number of epochs\",\n",
        "        \"titlefont\": {\n",
        "            \"size\": 18,\n",
        "            \"color\": \"#7f7f7f\"\n",
        "        }\n",
        "    },\n",
        "    \"yaxis\": {\n",
        "        \"title\": \"Accuracy\",\n",
        "        \"titlefont\": {\n",
        "            \"size\": 18,\n",
        "            \"color\": \"#7f7f7f\"\n",
        "        }\n",
        "    }\n",
        "}\n",
        "fig = Figure(data=data, layout=layout)\n",
        "fig.update_layout(hovermode=\"x unified\")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "04vQFKGpkX6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation\n",
        "\n",
        " - Unbalanced data, hence, accuracy is not a good idea.\n",
        " - Precision and recall are better and weighted average of these\n",
        " - metrics as well for overall model performance\n",
        "\n",
        " ```\n",
        " actual  prediction\n",
        " 0       1\n",
        " 0       0\n",
        " 0       0 \n",
        " 1       1\n",
        " 1       1\n",
        " 0       0\n",
        " ```\n",
        "\n",
        " Precision: 1/2, we have one correct prediction (TP) and total 3 positive predictions.\n",
        "\n",
        " Recall: 2/2, we have two correct predictions (TP) and total 2 actually positive data points. "
      ],
      "metadata": {
        "id": "XSQy-uV9rDKM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "lA5-yaFtvrMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Demo \"\"\"\n",
        "list1 = [0, 0, 0, 1, 1, 0]\n",
        "list2 = [1, 0, 0, 1, 1, 0]\n",
        "print(classification_report(list1, list2))"
      ],
      "metadata": {
        "id": "84mcnH9VvxJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model variable still holds the best model but \n",
        "# you can also reload a saved model like this\n",
        "best_model = keras.models.load_model('models/best_model.h5')"
      ],
      "metadata": {
        "id": "AP53XlIqkX33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_one_hot_encoded = (best_model.predict(padded_train)> 0.5).astype(\"int32\")\n",
        "y_pred_one_hot_encoded"
      ],
      "metadata": {
        "id": "OlZbvBXmrYxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = np.array(tf.argmax(y_pred_one_hot_encoded, axis=1))\n",
        "print(classification_report(train_data['emotion_label'], y_pred))"
      ],
      "metadata": {
        "id": "_4eT2NMOrYtn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Evaluation on Test Data\n",
        "y_pred_one_hot_encoded = (best_model.predict(padded_test)> 0.5).astype(\"int32\")\n",
        "y_pred = np.array(tf.argmax(y_pred_one_hot_encoded, axis=1))\n",
        "print(classification_report(test_data['emotion_label'], y_pred))"
      ],
      "metadata": {
        "id": "oTourMYUrYre"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}